%
% This is the LaTeX template file for lecture notes for CS294-8,
% Computational Biology for Computer Scientists.  When preparing
% LaTeX notes for this class, please use this template.
%
% To familiarize yourself with this template, the body contains
% some examples of its use.  Look them over.  Then you can
% run LaTeX on this file.  After you have LaTeXed this file then
% you can look over the result either by printing it out with
% dvips or using xdvi.
%
% This template is based on the template for Prof. Sinclair's CS 270.

\documentclass[11pt]{article}
\usepackage{charter}
\usepackage{graphicx}
\usepackage{url}
\usepackage{hyperref}
\usepackage{amsmath,amsthm,amssymb}
\usepackage{enumitem}

\setlength{\oddsidemargin}{0 in}
\setlength{\evensidemargin}{0 in}
\setlength{\topmargin}{-0.6 in}
\setlength{\textwidth}{6.5 in}
\setlength{\textheight}{8.5 in}
\setlength{\headsep}{0.75 in}
\setlength{\parindent}{0 in}
\setlength{\parskip}{0.1 in}

\newcommand{\PP}{\mathbb{P}}

%
% The following commands set up the lecnum (lecture number)
% counter and make various numbering schemes work relative
% to the lecture number.
%
\newcounter{lecnum}
\renewcommand{\thepage}{\thelecnum-\arabic{page}}
\renewcommand{\thesection}{\thelecnum.\arabic{section}}
\renewcommand{\theequation}{\thelecnum.\arabic{equation}}
\renewcommand{\thefigure}{\thelecnum.\arabic{figure}}
\renewcommand{\thetable}{\thelecnum.\arabic{table}}

%
% The following macro is used to generate the header.
%
\newcommand{\lecture}[5]{
   \pagestyle{myheadings}
   \thispagestyle{plain}
   \newpage
   \setcounter{lecnum}{#5}
   \setcounter{page}{1}
   \noindent
   \begin{center}
   \framebox{
      \vbox{\vspace{2mm}
    \hbox to 6.28in { {\bf Masters Bridge Program
                        \hfill Summer 2021} }
       \vspace{4mm}
       \hbox to 6.28in { {\Large \hfill Session {#1}: #2  \hfill} }
       \vspace{2mm}
       \hbox to 6.28in { {\it Instructor: #3 \hfill Contact: #4} }
      \vspace{2mm}}
   }
   \end{center}
   \markboth{Session #1: #2}{Session #1: #2}
   \vspace*{4mm}
}


%Use this command for a figure; it puts a figure in wherever you want it.
%usage: \fig{NUMBER}{SPACE-IN-INCHES}{CAPTION}
\newcommand{\fig}[3]{
			\vspace{#2}
			\begin{center}
			Figure \thelecnum.#1:~#3
			\end{center}
	}
% Use these for theorems, lemmas, proofs, etc.
\newtheorem{theorem}{Theorem}[lecnum]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}[theorem]{Example}
\newtheorem{exercise}[]{Exercise}
\newenvironment{proofof}[1]{{\em Proof of #1.}}{\hfill%\rule{2mm}{2mm}
\qed}

% **** IF YOU WANT TO DEFINE ADDITIONAL MACROS FOR YOURSELF, PUT THEM HERE:
\renewcommand{\P}{\mathbb{P}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\renewcommand{\H}{\mathcal{H}}
\renewcommand{\S}{\mathcal{S}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\MAP}{\mathrm{MAP}}
\newcommand{\z}{\mathbf{z}}
\newcommand{\e}{\mathbf{e}}
\newcommand{\w}{\mathbf{w}}
\newcommand{\x}{\mathbf{x}}
\newcommand{\Rp}{\mathbb{R}_{>0}}
\newcommand{\im}{\mathrm{Im}}
\newcommand{\sign}{\mathrm{sign}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\V}{\text{Var}}
\newcommand{\FF}{\mathcal{F}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\lbr}{\langle}
\newcommand{\rbr}{\rangle}
\newcommand{\indi}{\mathds{1}}

\begin{document}
\lecture{2}{Random variables and distributions}{Bryan Liu}{runjing\_liu@berkeley.edu}{2}

{\bf Supplemental reading: } Pitman \textit{Probability},  Chapters 2.1, 3.1, 3.2.

\section{Random variables}

A random variable $X$ is a variable
that represents a randomly produced number.
The set of possible values the variable $X$ can take on is called the
\textit{range}
of $X$.

Typically,
we will use capital letters towards the end of the alphabet to denote a random variable,
and lower case letters to denote constants.
For a random variable $X$ , we can ask, what is the probability that
$X = x$? Or $X \leq x$? Or $a \leq X \leq b$? And so forth.
We return to the same examples
that opened the previous session for concreteness.

\begin{example}[Rolling two dice]
  \label{ex:dice}

  Two dice are rolled, and we record the
  numbers showing on the top faces.
  Let $S$ be the sum of the two numbers.

  If the die are fair, then the probabilities of the values in the range of $S$
  are shown in Table~\ref{tab:distr_s}
  \begin{table}[!h]
    \centering
    \begin{tabular}{l|ccccccccccc}
      k & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12\\\hline
      $\P(S = k)$ & 1/36 & 2/36 & 3/36 & 4/36 & 5/36 & 6/36 & 5/36 & 4/36 & 3/36 & 2/36 & 1/36
    \end{tabular}
    \caption{The probability distribution of $S$.}
    \label{tab:distr_s}
  \end{table}


\qed
\end{example}

\begin{example}[Particle decay]
  \label{ex:particle_decay}
  Let $T$ be the time it takes for a radioactive particle to decay.
  The probability that it takes at least $t$ hours to decay is given by
  \begin{align*}
    \P(T\geq t) =
    \int_{t}^\infty \lambda \exp^{-\lambda s} \;ds,
  \end{align*}
  where $\lambda$ is a physical constant unique to the particle in study.
\qed
\end{example}

\begin{example}(Stock prices)
  \label{ex:log_stocks}
  Let $\Delta \log S$ be the change in log price of a stock after one unit time.
  The probability that the change lands between two numbers $a$ and $b$ is modeled
  as
  \begin{align}
    \P(\Delta \log S \in [a, b]) = \int_a^b \frac{1}{\sqrt{2\pi\sigma^2}}
    \exp^{-\frac{1}{2\sigma^2}(x - \mu)^2} \; dx
    \label{eq:normal_ex}
  \end{align}
  where, $\mu$ is the \textit{exponential growth rate of the stock}
  and $\sigma^2$ is the \textit{volatility} of the stock.
\qed
\end{example}

In comparing these examples with the motivating
examples from yesterday, you should see that
we have not really defined anything new.
Yesterday, we introduced the notion of \textit{events}
in an outcome space; here, random variables
determine events.
Every event can be expressed as $X\in B$ for some subset $B$, where
$B$ is a subset of the range of the random variable $X$.
The probability of this event is written
$\P(X\in B)$; yesterday, we simply wrote $\P(B)$.
By including the variable $X$, we are more
explicitly showing where the randomness is coming from
(randomness is coming from $X$).

\section{Distributions}

In the above examples, each random variable was assigned probabilities for
the values it could take on. These probabilities are called the
\textit{distribution} of the random variable.

Often these distributions have a name. The next exercise constructs our
first named distribution, the \textit{Binomial distribution}:

\begin{exercise}[The binomial distribution]
Consider a coin which comes up heads with probability $p$.
Consider flipping this coin $n$ times. Let $X$ be the number of
heads in the $n$ trials. Show that
\begin{align}
\P(X = k) = {n \choose k} p^k (1 - p)^{n - k}.
\label{eq:binom_distr}
\end{align}

\end{exercise}

When a random variable $X$ has assignment probabilities given by \eqref{eq:binom_distr},
we say that $X$ has a Binomial distribution with parameters $(n, p)$. The two constants
$n$ and $p$ specify this distribution.

Here are a few more examples of named distributions.

\begin{example}(Poisson)
A random variable $X$ which takes values on the non-negative integers is
\textit{Poisson distributed} with parameter $\lambda$ if
\begin{align}
  \P(X = k) = \frac{\lambda^k e^{-\lambda}}{k!}.
  \label{eq:poisson}
\end{align}

The Poisson distribution is often used to model the number of occurrences
of a certain event in a window of time. We will see its appearance in the next session.
\qed
\end{example}

\begin{example}(Exponential)
A random variable $X$ which takes values on the positive real line is
\textit{exponentially} distributed with parameter $\lambda$ if
\begin{align}
  \P(X \in [a, b]) =
  \int_a^b \lambda \exp^{-\lambda s} \;ds
  \label{eq:exponential}
\end{align}
for all real numbers $0 \leq a \leq b$.

The time until radioactive decay in Example~\ref{ex:particle_decay}
followed an exponential distribution.
\qed
\end{example}

\begin{example}(Gaussian)
A random variable $X$ which takes values on the real line follows a
\textit{Gaussian} or \textit{normal} distribution with mean $\mu$ and variance
$\sigma^2$ if
\begin{align}
  \P(X \in [a, b]) =
  \int_a^b \frac{1}{\sqrt{2\pi\sigma^2}}
  \exp^{-\frac{1}{2\sigma^2}(x - \mu)^2} \; dx
  \label{eq:normal}
\end{align}
for all real numbers $a \leq b$.

Many natural phenomenon such as the distribution of human heights, IQ scores, and
measurement error in physical experiments are well-approximated by the familiar
bell-shaped curve that characterizes the normal distribution.

The normal distribution is ubiquitous in statistical inference as a result of
the celebrated central limit theorem, which says, loosely, that averages
of random variables will converge to a normal distribution. We will explore this further in the next session.
\qed
\end{example}


\subsubsection*{Notation}

When a random variable follows some distribution,
we will use the $\sim$ symbol. For example,
if $X$ is normally distributed with parameters
$(\mu, \sigma^2)$, we will write
\begin{align*}
  X \sim \text{Normal}(\mu, \sigma^2).
\end{align*}

We will often use $F$ to denote a generic distribution,
and will write $X\sim F$, read as ``$X$ follows distribution $F$", or ``$X$ is sampled from distribution $F$."

\subsubsection*{Discrete vs continuous random variables}

For a \textit{discrete} random variable $X$, the distribution of $X$ is specified
by the probabilities $\P(X = x)$, for all values $x$ in the range of $X$.
The function $f(x) := \P(X = x)$ is called the \textit{probability mass function}, or \textit{p.m.f}.
The sum of two dice rolls, Binomial random variables, and Poisson random variables
are discrete, with probability mass functions displayed in
Table~\ref{tab:distr_s}, Equation~\eqref{eq:binom_distr},
and Equation~\eqref{eq:poisson}, respectively.

For a \textit{continuous} random variable $X$, such as exponential or normal random variables,
the probability $\P(X = x) = 0$ for any scalar $x$.  Instead, probabilities were defined on sets
using integrals (\ref{eq:exponential},\ref{eq:normal}).
The integrand is called a \textit{probability density function} (or simply a ``density", or abbreviated \textit{p.m.f}). Loosely,
we can interpret a density $f(x)$ as specifying the probability that $X$ lies
an infinitesimal interval around $x$, that is
\begin{align*}
  \P(X \in dx) = f(x)\;dx.
\end{align*}

For generic sets $[a, b]$ in $\R$, we sum the infinitesimal probabilities
to obtain
\begin{align*}
  \P(X\in[a, b]) = \int_a^b f(x)\;dx
\end{align*}

In later sessions, we will have more exercises on manipulating probability density functions.
Our current definition will suffice for the concepts introduced below.

\subsection{Conditional distributions}
Last session, we defined conditional probabilities and independence for events.
These definitions are similarly defined in the context of random variables.
\begin{itemize}
  \item {\bf Conditional distributions: }\footnote{
  We will come back to this formula specifically for continuous random variables ...
  in particular we need to be careful if we want to condition on the event $Y = y$,
  which has probability 0 if $Y$ is continuous.
  }
  Let $X$ and $Y$ be two random variables. Suppose we know that $Y\in B$, $B$
  being a subset of the range of $Y$. Then the
  \textit{conditional distribution} of $X$ given $Y\in B$ is
  \begin{align*}
    \P(X\in A | Y \in B) = \frac{\P(X\in A \text{ and } Y \in B)}{\P(Y \in B)}.
  \end{align*}
  \item {\bf Independence: } Random variables $X$ and $Y$ are independent if
  \begin{align*}
    \P(X\in A | Y \in B) = \P(X\in A)
  \end{align*}
  for all sets $A$ and $B$.

  Intuitively, $X$ and $Y$ are independent if the values of $X$ are unaffected
  by the values of $Y$.
\end{itemize}

\begin{example}[Conditional distributions and independence]
Suppose I roll two die.
Let $X_1$ and $X_2$ be the result of first and second dice, respectively.
$X_1$ and $X_2$ are independent random variables, because conceivably,
the value of one dice roll does not affect the probability distribution of the other dice roll:
each dice has probability $1/6$ on numbers $\{1, ..., 6\}$
regardless of the outcome of the other dice.

Let $S = X_1 + X_2$ be the sum of two dice rolls.
$X_1$ and $S$ are not independent. For example, given that $X_1 = 3$, then
$S$ has the conditional distribution displayed in Table~\ref{tab:cond_s}
(compare with Table~\ref{tab:distr_s}).

\begin{table}[!h]
  \centering
  \begin{tabular}{l|ccccccccccc}
    k& 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12\\\hline
    $\P(S = k)$ & 0 & 0 & 1/6 & 1/6 & 1/6 & 1/6 & 1/6 & 1/6 & 0 & 0 & 0
  \end{tabular}
  \caption{Conditional distribution of $S$ given $X_1 = 3$.}
  \label{tab:cond_s}
\end{table}


\end{example}

\section{Expectation and variance}

We now turn to computing scalar quantities which summarize random variables
and their distributions.
We start with

\fbox{\begin{minipage}{\textwidth}
The \textbf{expectation} (or \textbf{expected value}) of a random variable $X$, denoted
$\E(X)$, is defined as
\begin{align*}
\E(X) = \sum_{x} x \P(X = x)
\end{align*}
if $X$ is a discrete random variable.

If $X$ is a continuous random variable with probability density function $f$, then
\begin{align*}
  \E(X) = \int_{-\infty}^\infty x f(x)\; dx.
\end{align*}

\end{minipage}}

We record some properties of expectations:
\begin{itemize}
  \item {\bf Linearity: } For scalars $a, b\in R$,
  \begin{align*}
    \E(aX + b) = a\E(X) + b.
  \end{align*}
  \item {\bf Addition rule: } For two random variables $X$ and $Y$,
  \begin{align*}
    \E(X + Y) = \E(X) + \E(Y).
  \end{align*}
  \item {\bf Multiplication rule: } For two \textit{independent}
  random variables $X$ and $Y$,
  \begin{align*}
    \E(XY) = \E(X)\E(Y).
  \end{align*}
\end{itemize}

Notice that we do not require independence for addition,
but we do require
independence for multiplication.


\begin{exercise}[]
  $\;$\vspace{-1em}

  \begin{enumerate}[label = (\alph*)]
    \item Let $S$ be the sum of two dice rolls (see Example~\ref{ex:dice}). Compute
    the expectation of $S$.
    \item Show that if $X$ is Poisson distributed with parameter $\lambda$, then
    $X$ has expectation $\lambda$.
    \item Show that if $X$ is exponentially distributed with parameter $\lambda$,
    then the expectation of $X$ is $1/\lambda$.
    \item Confirm that if $X$ is normally distributed with parameters $(\mu, \sigma^2)$,
    then the expectation of $X$ is $\mu$
    (assume all integrals converge).
  \end{enumerate}
\end{exercise}

\begin{exercise}[]
  Let $S_n$ be the sum of numbers obtained from $n$ dice. Find $\E(S_n)$.
\end{exercise}

\begin{exercise}[]
  Let $X$ be Binomially distributed with parameters $(n, p)$.
  Show that $\E(X) = np$.
\end{exercise}

\begin{exercise}[Markov's inequality]
  Let $X$ be a non-negative random variable with expectation $\mu$.
  Show that for any number $a \geq 0$
  \begin{align}
    \P(X \geq a) \leq \frac{\E(X)}{a}
    \label{eq:markov}
  \end{align}
\end{exercise}

We use the definition of an expectation to broaden our scope of distributional summaries.
Next, we consider the \textit{variance} of a random variable.

\fbox{\begin{minipage}{\textwidth}
Let $\mu = \E(X)$. The \textbf{variance} of a random variable $X$, abbreviated
$\V(X)$, is defined as the expected squared deviation of $X$ from $\mu$,
\begin{align*}
\V(X) = \E\Big((X - \mu)^2\Big).
\end{align*}

\end{minipage}}

Next, we now record some properties of variances:
\begin{itemize}
  \item {\bf Scaling and shifting: } For scalars $a, b\in R$,
  \begin{align*}
    \V(aX + b) = a^2\V(X).
  \end{align*}
  \item {\bf Addition rule: } For two \textit{independent}
  random variables $X$ and $Y$,
  \begin{align*}
    \V(X + Y) = \V(X) + \V(Y).
  \end{align*}
\end{itemize}

\begin{exercise}[Alternative formula for variance]
  Show that $\V(X) = \E(X^2) - \E(X)^2$.
\end{exercise}

\begin{exercise}[]
  $\;$\vspace{-1em}

  \begin{enumerate}[label = (\alph*)]
    \item Let $X$ be the number returned by a single dice roll. Compute
    the variance of $X$.
    \item Show that if $X$ is Poisson distributed with parameter $\lambda$, then
    $\V(X)=\lambda$.
    \item Show that if $X$ is exponentially distributed with parameter $\lambda$, then
    $\V(X)=1/\lambda^2$.
  \end{enumerate}
\end{exercise}


\begin{exercise}[iid random variables]
  Suppose $X_1,..., X_n$ are random variables drawn independently from a
  common distribution $F$. Let $\mu$ and $\sigma^2$ be the mean and variance,
  respectively, of the distribution $F$. Let
  \begin{align*}
    \bar{X} = \frac{1}{n} \sum_{i=1}^n X_i
  \end{align*}
  be the average of the $n$ random variables. Show that

  \begin{enumerate}[label = (\alph*)]
    \item $\E(\bar{X}) = \mu$.
    \item $\V(\bar{X}) = \frac{\sigma^2}{n}$.
  \end{enumerate}
\end{exercise}

\begin{exercise}[Chebychev's inequality]
  Use Markov's inequality \eqref{eq:markov} to show that
  \begin{align*}
    \P(|X - \E(X)| \geq a) \leq \frac{\V(X)}{a^2}.
  \end{align*}
\end{exercise}

Chebychev's inequality puts an upper bound on the \textit{tail probability},
the probability that a random variable $X$ is far from its mean.

Tail probabilities are of particular interest in hypothesis testing.
Here, the random variable $X$ would represent a test statistic;
if the the deviation of the observed statistic from its mean occurs with small probability under
the null hypothesis,
then we would consider this evidence in favor or \textit{rejecting} the null.
Chebychev inequality is one way to show that the probability of deviations are small.
This inequality is useful because it does not depend on distributional assumptions of $X$
(such as normality); we only need to know (or be able to approximate) its mean and variance.

\begin{exercise}[Empirical distribution]
Suppose I have collected $n$ data points $x_1, ..., x_n$.
The \textit{empirical distribution}
is defined as
\begin{align}
  \P(X = x) = \frac{\#\{x_i = x\}}{n}.
  \label{eq:empirical}
\end{align}

Show that if $X$ is drawn from the empirical distribution, then
\begin{enumerate}[label = (\alph*)]
  \item What is $\E(X)$ in terms of $x_1, ..., x_n$?
  \item What is $\V(X)$?
\end{enumerate}
\label{exer:empirical}
\end{exercise}

In statistics, we usually view the data points $x_1, ..., x_n$ as coming from some
data generating process which is unknown to us. Let $F$ represent the unknown, true
data generating distribution. We want to know things about $F$, for example its mean
and variance.
But, $F$ is unknown. So what do statisticians do?

The \textit{plug-in principle} says that we can try to replace the unknown
distribution $F$ with the empirical distribution $\hat F$ -- ``empirical" because
$\hat F$ is constructed from observed data using
\eqref{eq:empirical} -- and then compute quantities of interest,
such as the mean and variance,
using $\hat F$ in place of $F$.
Theory\footnote{specifically, the Glivenko–Cantelli theorem}
says that for large $n$, $\hat F$ should well-approximate $F$.
The plug-in principle
appears in many forms in statistical practice; the exercise with the mean and variance above
is a simple example.

\subsection{Predictions}

We conclude this session with a discussion of risk-minimization for prediction problems.
Suppose we have a random variable $X$ coming from some distribution $F$.
In machine learning applications, we would like to predict the value of this random variable.
How should we make this prediction?

One possible framework is to define a \textit{loss function} $L(x, b)$, which is
the penalty I pay for guessing $b$ if the true value of $X$ is $x$.
The goal is to choose $b$ to minimize the expected loss, or \textit{risk}, defined as
\begin{align}
  r(b) = \E(L(X, b)).
  \label{eq:risk}
\end{align}

\begin{exercise}[]
  $\quad$\vspace{-1em}

  \begin{enumerate}[label = (\alph*)]
    \item Suppose our penalty is the squared error, $L(x, b) = (x - b)^2$. Show that $b = \E(X)$ minimizes
    \eqref{eq:risk}.
    \item Suppose our penalty is the absolute error, $L(x, b) = |x - b|$. Show that the median of the
    distribution of $X$ minimizes \eqref{eq:risk}.
  \end{enumerate}
\end{exercise}


\begin{exercise}[The newsvendor problem]
  I am operating a newspaper stand, and I need to decide the number of newspapers
  I should stock every day.
  Let $X$ be the number of newspapers I sell each day, which I model as
  a random quantity with
  distribution $F$.
  I buy newspapers at $C$-dollars per paper, and sell to customers for a price $P > C$.
  Overstocking results in wasted inventory, while under-stocking results in lost sales.
  By choosing to stock $b$ items, my profit when $x$ items
  are sold is
  \begin{align}
    \textrm{Profit}(x, b) = P\min(b, x) - Cb.
  \end{align}
  Define the loss to be $L(x, b) = - \textrm{Profit}(x, b)$, so that
  minimizing $L$ is equivalent to maximizing profit.

  Show that for this profit model, the optimal $b$ is given by the $(\frac{P - C}{P})$-th
  quantile of the distribution $F$.

\end{exercise}

$\quad$

To minimize the risk in \eqref{eq:risk}, the data generating distribution
$F$ is typically not known.
The plug-in principle is in play once again, resulting in technique of
\textit{empirical risk minimization} in machine learning.
Here, the expectation over $F$ in \eqref{eq:risk} is replaced with the empirical
distribution $\hat F$.

In the case of squared error loss, we saw that the optimal predictor is the
expectation of $F$.
The optimal predictor is unknown if $X$ comes from an unknown distribution $F$.
The plug in principle says that we could try to replace $F$ with $\hat F$,
the empirical distribution.
The resulting predictor is the expectation of $\hat F$, which by
Exercise~\ref{exer:empirical} we showed is the equal to the sample mean.

\end{document}
