%
% This is the LaTeX template file for lecture notes for CS294-8,
% Computational Biology for Computer Scientists.  When preparing
% LaTeX notes for this class, please use this template.
%
% To familiarize yourself with this template, the body contains
% some examples of its use.  Look them over.  Then you can
% run LaTeX on this file.  After you have LaTeXed this file then
% you can look over the result either by printing it out with
% dvips or using xdvi.
%
% This template is based on the template for Prof. Sinclair's CS 270.

\documentclass[11pt]{article}
\usepackage{charter}
\usepackage{graphicx}
\usepackage{url}
\usepackage{hyperref}
\usepackage{amsmath,amsthm,amssymb}
\usepackage{enumitem}

\setlength{\oddsidemargin}{0 in}
\setlength{\evensidemargin}{0 in}
\setlength{\topmargin}{-0.6 in}
\setlength{\textwidth}{6.5 in}
\setlength{\textheight}{8.5 in}
\setlength{\headsep}{0.75 in}
\setlength{\parindent}{0 in}
\setlength{\parskip}{0.1 in}

\newcommand{\PP}{\mathbb{P}}

%
% The following commands set up the lecnum (lecture number)
% counter and make various numbering schemes work relative
% to the lecture number.
%
\newcounter{lecnum}
\renewcommand{\thepage}{\thelecnum-\arabic{page}}
\renewcommand{\thesection}{\thelecnum.\arabic{section}}
\renewcommand{\theequation}{\thelecnum.\arabic{equation}}
\renewcommand{\thefigure}{\thelecnum.\arabic{figure}}
\renewcommand{\thetable}{\thelecnum.\arabic{table}}

%
% The following macro is used to generate the header.
%
\newcommand{\lecture}[5]{
   \pagestyle{myheadings}
   \thispagestyle{plain}
   \newpage
   \setcounter{lecnum}{#5}
   \setcounter{page}{1}
   \noindent
   \begin{center}
   \framebox{
      \vbox{\vspace{2mm}
    \hbox to 6.28in { {\bf Masters Bridge Program
                        \hfill Summer 2021} }
       \vspace{4mm}
       \hbox to 6.28in { {\Large \hfill Session {#1}: #2  \hfill} }
       \vspace{2mm}
       \hbox to 6.28in { {\it Instructor: #3 \hfill Contact: #4} }
      \vspace{2mm}}
   }
   \end{center}
   \markboth{Session #1: #2}{Session #1: #2}
   \vspace*{4mm}
}


%Use this command for a figure; it puts a figure in wherever you want it.
%usage: \fig{NUMBER}{SPACE-IN-INCHES}{CAPTION}
\newcommand{\fig}[3]{
			\vspace{#2}
			\begin{center}
			Figure \thelecnum.#1:~#3
			\end{center}
	}
% Use these for theorems, lemmas, proofs, etc.
\newtheorem{theorem}{Theorem}[lecnum]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}[theorem]{Example}
\newtheorem{exercise}[]{Exercise}
\newenvironment{proofof}[1]{{\em Proof of #1.}}{\hfill%\rule{2mm}{2mm}
\qed}

% **** IF YOU WANT TO DEFINE ADDITIONAL MACROS FOR YOURSELF, PUT THEM HERE:
\renewcommand{\P}{\mathbb{P}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\renewcommand{\H}{\mathcal{H}}
\renewcommand{\S}{\mathcal{S}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\MAP}{\mathrm{MAP}}
\newcommand{\z}{\mathbf{z}}
\newcommand{\e}{\mathbf{e}}
\newcommand{\w}{\mathbf{w}}
\newcommand{\x}{\mathbf{x}}
\newcommand{\Rp}{\mathbb{R}_{>0}}
\newcommand{\im}{\mathrm{Im}}
\newcommand{\sign}{\mathrm{sign}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\FF}{\mathcal{F}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\lbr}{\langle}
\newcommand{\rbr}{\rangle}
\newcommand{\indi}{\mathds{1}}

\begin{document}
\lecture{1}{Basic concepts}{Bryan Liu}{runjing\_liu@berkeley.edu}{1}

The materials for this workshop are
adapted from Jim Pitman's undergraduate text on probability.
A pdf can be found for free at
\begin{center}
  \url{https://link.springer.com/book/10.1007/978-1-4612-4374-8}
\end{center}

This first session comes from Chapter 1.

\section{Probability spaces}

The building blocks of probability theory are three ingredients:

\fbox{\begin{minipage}{\textwidth}
\begin{itemize}
  \item {\bf An outcome space: } the set of possible outcomes, denoted $\Omega$.
  \item {\bf Events: } subsets of the outcome space, often denoted with a capital letter,
  e.g. $A\subseteq \Omega$.
  \item {\bf Probability: } a function which maps events to a real number
  between 0 and 1. We use $\P$ to denote such a function,
  in which case $\P(A)$ represents the probability of event $A$.
\end{itemize}
\end{minipage}}

\begin{example}[Rolling two dice]

  Two dice are rolled, and number on the top faces are recorded.

  The \textit{outcome space} are the pairs,

\begin{align*}
  \Omega = \begin{Bmatrix}
    (1, 1), & (1, 2), & (1, 3), & (1, 4), & (1, 5), & (1, 6) \\
    (2, 1), & (2, 2), & (2, 3), & (2, 4), & (2, 5), & (2, 6) \\
    (3, 1), & (3, 2), & (3, 3), & (3, 4), & (3, 5), & (3, 6) \\
    (4, 1), & (4, 2), & (4, 3), & (4, 4), & (4, 5), & (4, 6) \\
    (5, 1), & (5, 2), & (5, 3), & (5, 4), & (5, 5), & (5, 6) \\
    (6, 1), & (6, 2), & (6, 3), & (6, 4), & (6, 5), & (6, 6)
  \end{Bmatrix}.
\end{align*}

  \textit{Events} are subsets of the outcome space. One such event
  might be ``the sum of the two numbers is 5". This event is the subset
  %
  \begin{align*}
    A = \begin{Bmatrix} (1, 4), & (2, 3), & (3, 2), & (4, 1) \end{Bmatrix}
  \end{align*}
  %
  Assuming the die are fair, each pair in the event space is assigned to have
  probability $1/36$, and the probability of the event above is
  \begin{align*}
   \P(\text{the sum of the two numbers is 5}) = \frac{4}{36} = \frac{1}{9}
  \end{align*}

\qed
\end{example}

\begin{example}[Particle decay]
  We measure the time it takes for a radioactive particle to decay.
  The \textit{outcome space} is $\Omega = \R^{+}$, the positive real line.

  Events are subsets of the positive real line. For example, one
  event might be ``it takes at least 3 hours for the particle to decay".

  The probability of this event is given by
  \begin{align*}
    \P(\text{at least 3 hours for the particle to decay}) =
    \int_{3}^\infty \lambda \exp^{-\lambda t} \;dt,
  \end{align*}
  where $\lambda$ is a physical constant unique to the particle in study.

  In general, an event $A$ is of the form
  \begin{align*}
    A = \{t : t \geq a \text{ and } t \leq b\},
  \end{align*}
  where $t$ is the decay time, while $a$ and $b$ are real numbers.
  The probability of such events is
  \begin{align}
    \P(A) =
    \int_a^b \lambda \exp^{-\lambda t} \;dt.
    \label{eq:exponential_ex}
  \end{align}

  When the probability of decay times follow the formula in \eqref{eq:exponential_ex},
  we say that the decay time is \textit{exponentially distributed}.

\qed
\end{example}

\begin{example}(Stock prices)
  Let $S_0$ be the initial stock price, and $S_1$ be its price after one unit time.
  Consider the log ratio of stock prices,
  \begin{align*}
    \Delta \log S := \log\frac{S_1}{S_0}.
  \end{align*}

  We model the log ratio as a random quantity.
  The outcome space is the real line. Events are subsets of the real line,
  for example, ``the log ratio is greater than $a$ but less than $b$",
  $a$ and $b$ real numbers. In math, an event $A$ is the set
  \begin{align*}
    A = \{\Delta \log S \in [a, b]\}.
  \end{align*}

  The probability of such events are modeled as
  \begin{align}
    \P(A) = \int_a^b \frac{1}{\sqrt{2\pi\sigma^2}}
    \exp^{-\frac{1}{2\sigma^2}(x - \mu)^2} \; dx
    \label{eq:normal_ex}
  \end{align}

  Here, $\mu$ is the \textit{exponential growth rate of the stock} (exponential because
  we are working with log-prices) and $\sigma^2$ is the \textit{volatility} of the stock.

  Random quantities with event probabilities
  given by \eqref{eq:normal_ex} are called \textit{normally distributed}.
\qed
\end{example}

In the first two examples, the assigned probabilities are more or less well-motivated
by our understanding of the laws of physics. In the last example, the assumption of
a normal distribution is a modeling choice, which may or may not be accurate.
An important job for the statistician is arguing that the modeling choice is appropriate,
either with theoretical derivations or with empirical evidence.


\section{Rules of probability}

Probabilities must satisfy

\fbox{\begin{minipage}{\textwidth}
\begin{itemize}
  \item \textbf{non-negativity}: $\P(A) \geq 0$ for events $A$.
  \item \textbf{additivity}: $\P(A \cup B) = \P(A) + \P(B)$ if $A$ and $B$ are
  disjoint.
  \item \textbf{total one}: $\P(\Omega) = 1$.
\end{itemize}
\end{minipage}}

From these basic rules we can derive
\begin{itemize}
  \item \textbf{The complement rule}: $\P(\text{not} A) = 1 - \P(A)$.
  \item \textbf{The difference rule}: if $A\subseteq B$, then $\P(B \text{ but not } A) = \P(B) - \P(A)$.
  \item \textbf{Inclusion-exclusion}: $\P(A\cup B) = \P(A) + \P(B) - \P(A\cap B)$.
\end{itemize}
IN CLASS: proof by picture.

Next, we extend the inclusion-exclusion principle to derive Boole's inequality.
\begin{exercise}[Boole's inequality]

  $\quad$\vspace{-1em}

  \begin{enumerate}[label = (\alph*)]
    \item Argue that for any events $A, B$,
    \begin{align*}
      \P(A \cup B)\leq \P(A) + \P(B)
    \end{align*}
    \item Use induction to argue that for any set of events $B_1, ..., B_n$,
    \begin{align}
    \P(\cup_{i=1}^n B_i) \leq \sum_{i=1}^{n} \P(\cup_{i = 1}^n B_i)
    \label{eq:booles}
    \end{align}
  \end{enumerate}
\end{exercise}


\begin{example}[Bonferroni's correction]
This simple inequality \eqref{eq:booles} is useful in multiple testing situations.
Suppose we are running $n$ trials (say to test the effect of $n$ different drugs),
and for each trial we set up a level-$\alpha$
hypothesis test.
Let $B_i$ be the event that we reject the $i$-th hypothesis.
If our test is correctly set-up, then we must have $\P(B_i) = \alpha$ for all $i$,
where the probability $\P$ is computed under the assumptions of the null hypothesis.

Notice however, that in general, we must have $\P(\cup_i B_i) \geq \alpha$,
so the probability that we make at least one false rejection is greater than $\alpha$.

To control the probability of making even one false rejection then, we design
a test such that the probability of rejection for each test is instead $\alpha / n$ --
that is, $\P(B_i) = \alpha / n$ for all $i$. In this case,
Boole's inequality shows that
\begin{align*}
  \P(\cup_{i=1}^n B_i) \leq \sum_{i=1}^{n} \P(\cup_{i = 1}^n B_i)
  = \alpha.
\end{align*}

This correction of $\alpha$ values by dividing by $n$ is known as \textit{Bonferroni's correction}.
Notice that we did not need any assumptions on the nature of the events $B_i$;
we only assumed we have correctly specified hypothesis tests, which makes this
correction of general interest.

However, correcting an $\alpha$-rejection level to an $(\alpha / n)$-rejection level
considerably decreases the power of the tests (i.e. it is harder to make any true rejections).
When we know more about the nature of the events, e.g. their correlation structure,
it is often possible to employ less stringent corrections.

\qed
\end{example}

\section{Conditional probabilities}

Given two events $A$ and $B$, we can compute the probability that $A$ occurs
if we know that $B$ occurs. This is known as a conditional probability,
written $\P(A | B)$.

The general formula is given by

\fbox{\begin{minipage}{\textwidth}
\vspace{-1em}
\begin{align}
  \P(A | B) = \frac{\P(A \cap B)}{\P(B)}.
  \label{eq:conditional_prob}
\end{align}
\end{minipage}}

IN CLASS: show by picture.

We can re-write \eqref{eq:conditional_prob} as
\begin{align}
  \P(A\cap B) = \P(A | B) \P(B)
  \label{eq:multiplication}.
\end{align}

Events $A$ and $B$ are \textbf{independent} if $P(A | B) = P(A)$.
For independent events, \eqref{eq:multiplication} becomes
\begin{align}
  \P(A\cap B) = \P(A) \P(B)
  \label{eq:indep}.
\end{align}

\begin{exercise}[Sequential vs parallel components]
A system consists of two components $C_1$ and $C_2$. Suppose the failure probability
of $C_1$ is 0.05, while the failure probability of $C_2$ is 0.02.
The failure events are independent.
\begin{enumerate}[label = (\alph*)]
  \item Suppose the system is connected in series, so if one of the two component
  fails, the entire system fails. What is the probability that the system works?
  \item Suppose the system is connected in parallel, so as long as one of the
  component works, the system works. What is the probability that
  the system works?
\end{enumerate}


\end{exercise}

\begin{exercise}[Conditional probabilities]
Suppose there is a 40\% chance of raining Monday. If it rains Monday,
then the probability that it rains Tuesday is 75\%. But if
it does not Monday, then the probability that it rains on Tuesday
falls to 15\%. Calculate the following probabilities that on Monday and Tuesday,

\begin{enumerate}[label = (\alph*)]
  \item It rains at least once.
  \item It rains exactly once.
  \item It rains on Tuesday.
\end{enumerate}
\label{ex:raining}
\end{exercise}

IN CLASS draw tree diagram. Using the above tree diagram, we can derive

\fbox{\begin{minipage}{\textwidth}
\textbf{The rule of average conditional probabilities:}
\begin{align}
\P(A) = \P(A | B_1) \P(B_1) + ... + \P(A | B_n)\P(B_n)
\label{eq:avg_cond_probs}
\end{align}
where $B_1, ..., B_n$ is a \textit{partition} of $\Omega$, meaning
that the $B_i$ are disjoint and that $\cup_i B_i = \Omega$.

\end{minipage}}

\begin{exercise}[Stratified sampling]
Three high schools have senior class of size 100, 400, and 500, respectively.
Consider two schemes for selecting a student from among the three senior classes:
\begin{enumerate}[label=\Roman*]
  \item Make a list of all 1000 seniors, and choose a student at random from this list.
  \item Pick one school at random, then pick a student at random from the senior class in that school.
\end{enumerate}
Are these sampling schemes equivalent? Why or why not?

Consider a third scheme: where we pick school $i$ with probability $p_i$ (so $p_1 + p_2 + p_3 = 1$),
and then pick a student at random from the senior class in that school. Find the probabilities which make this last scheme equivalent to scheme I.

\end{exercise}

\section{Bayes rule}

We can combine the conditional probability formula \eqref{eq:conditional_prob} and
the rule of average conditional probabilities \eqref{eq:avg_cond_probs} to arrive
at {\bf Bayes rule}:

\fbox{\begin{minipage}{\textwidth}
For a partition of all possible outcomes $B_1, ..., B_n$,
\begin{align}
\P(B_i | A) = \frac{\P(A|B_i)\P(B_i)}{\P(A | B_1) \P(B_1) + ... + \P(A | B_n)\P(B_n)}.
\label{eq:bayes_rule}
\end{align}

\end{minipage}}

\begin{exercise}[Conditional probabilities continued]
  Return to the conditional probabilities in Exercise~\ref{ex:raining}.
  Suppose I was out of town Monday, so I don't know if it rained then. I come back
  on Tuesday, and saw that it rained. Apply Bayes rule to compute the probability
  that it rained Monday.
  \footnote{To a frequentist, this question would be nonsensical: Monday has already
  occurred, so either it rained or it did not rain; there is no sense in assigning a
  probability to this event.
  In the mind of a Bayesian however, the event ``it rained on Monday"
  is unobserved -- and therefore random. The probability assigned to this event
  quantifies the uncertainty in the occurrence of the unobserved event.
  The Bayesian will continue to view this event as random
  until more information is collected, for example, by asking a friend
  who was in town whether or not it rained on Monday.  }
\end{exercise}

\begin{exercise}[Identical or fraternal twins]\footnote{
  Example taken from Chapter 3 of \url{https://web.stanford.edu/~hastie/CASI/}.
  }
  A mother finds out via sonogram that she is going to have twin boys.
  She wants to know, what is the probability that her twins will be
  identical rather than fraternal? The doctor tells her that in the United States, one-third of twin births
  are identical, while two-thirds are fraternal.
  For identical twins, the siblings must be of the same sex; for fraternal births,
  each sibling has a 50/50 chance of being male or female,
  independently of each other.
  Apply Bayes rule to compute probability that the mother's twins will be fraternal.
\end{exercise}

\begin{exercise}[Medical diagnosis]
  A diagnostic test for a type of cancer has a \textit{sensitivity} of 98\% and a
  \textit{specificity} of 90\%. Here,
  \begin{itemize}
    \item \textbf{sensitivity} is the probability that a test returns a positive result if the
individual has the disease.
    \item \textbf{specificity} is the probability that a test returns a negative result if the
individual does not have the disease.
  \end{itemize}

  Suppose I walk into the doctor's office and get a test for this type of cancer.
  I test positive. Consider three scenarios:
  \begin{enumerate}[label = (\alph*)]
    \item Going home, I Google that this cancer occurs in 0.2\% of the
    adult population in the United States.
    Being a statistician, I use Bayes rule to compute the probability that I have
    this cancer. What is the probability?
    \item But wait. Upon talking with my doctor again, he tells me that in his experience,
    smokers are more likely than the general public to have this cancer.
    In fact, about 20\% of smokers develop this cancer. My doctor is well-trained in
    probability, and she knows that I smoke.
    She uses Bayes rule to compute the probability that I have cancer. What is
    this probability?
    \item I go visit a geneticist who sequences my genome.
    He tells me that among people with similar genetic characteristics as mine,
    about 5\% of people develop this cancer.
    The geneticist then uses Bayes rule to compute the probability that
    I have cancer. What is this probability?
  \end{enumerate}
  \label{ex:diagnostic}
\end{exercise}

\subsubsection*{Discussion}

Bayes rule is a mathematical formula for turning observed data into
inferences concerning unknown quantities.
In the previous exercise, the observed data is that I have a positive diagnostic test.
The unknown quantity that I would like to know is whether or not I have cancer.
In story of the mother with twins, the observed data is that her
twins are both boys. The unknown quantity is whether the twins are identical or fraternal.

Crucially, the inferences made using Bayes rule depend on specifying a \textit{prior probability},
that is, the background probability of the unknown event before seeing any data.
In the twin example, the doctor can go into a hospital database of all births in the United States,
and see what fraction of twins were fraternal, and what fraction were identical.
In this case, these proportions were one-third and two-thirds, respectively.

However, as the medical diagnosis example tries to illustrate, this prior probability
may not be straight-forward to specify. Which prior probability should I use, and which is correct? My Google search, my doctor,
or my geneticist? The resulting conclusion about my cancer diagnosis
depends what assumptions we make; and the assumptions we make depend
on the available knowledge at hand.

More fundamentally, how can we interpret the
probability, given that it changes based on the
information at hand or based on expert opinion?
The answer depends on how we define the \textit{population
of interest}.\footnote{
Defining the population is the
first step in applied statistical analysis,
argues Bin Yu in
\url{https://www.stat.berkeley.edu/~binyu/ps/papers2018/AI+Stat18.pdf}
}
Let us take scenario (c) in Exercise~\ref{ex:diagnostic}.
Here, the \textit{implicit theoretical population is the set of
individuals with similar genetic information as me}.
Suppose I sample 1000 individuals from this theoretical
population, and test each individual.
Then each individual would fall in one of four categories:
(test positive, diseased); (test positive, not diseased);
(test negative, diseased); (test negative, not diseased).
Based on the probability model described in
Exercise~\ref{ex:diagnostic}, the counts
of individuals falling in each categories would be
approximately
\begin{table}[!h]
  \centering
  \begin{tabular}{l|cc|c}
    & Test positive & Test negative & Total \\\hline
  Diseased & 49 & 1 & 50 \\
  Not diseased & 95 & 855 & 950\\ \hline
  Total & 144 & 856 & 1000
  \end{tabular}
\end{table}.

If I am a member of this sample of 1000 individuals
from the theoretical population, and I know that
I test positive, then this places me in the first
column of the table above.
Examining the first column of the table, I see
that $49 / 144$ of these positive individuals
have the disease. I conclude then,
that I have a $49 / 144 = .34$ myself
of having this disease.

This demonstrates the frequency interpretation
probability: if I sample a set of
individuals from my theoretical population,
then I would expect
about 34\% of these individuals who test
positive will be actually diseased.
Notice that this probability depends on the
prevalence of this disease in the population -- i.e.
how I define my theoretical population.

Bayes rule is a provable mathematical fact about
probabilities and events.
Going from mathematical principles to real data
applications however, requires care in
thinking about what probabilities, and our resulting
inferences, actually tell us about the world.


\end{document}
