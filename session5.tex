%
% This is the LaTeX template file for lecture notes for CS294-8,
% Computational Biology for Computer Scientists.  When preparing
% LaTeX notes for this class, please use this template.
%
% To familiarize yourself with this template, the body contains
% some examples of its use.  Look them over.  Then you can
% run LaTeX on this file.  After you have LaTeXed this file then
% you can look over the result either by printing it out with
% dvips or using xdvi.
%
% This template is based on the template for Prof. Sinclair's CS 270.

\documentclass[11pt]{article}
\usepackage{charter}
\usepackage{graphicx}
\usepackage{url}
\usepackage{hyperref}
\usepackage{amsmath,amsthm,amssymb}
\usepackage{enumitem}

\setlength{\oddsidemargin}{0 in}
\setlength{\evensidemargin}{0 in}
\setlength{\topmargin}{-0.6 in}
\setlength{\textwidth}{6.5 in}
\setlength{\textheight}{8.5 in}
\setlength{\headsep}{0.75 in}
\setlength{\parindent}{0 in}
\setlength{\parskip}{0.1 in}

\newcommand{\PP}{\mathbb{P}}

%
% The following commands set up the lecnum (lecture number)
% counter and make various numbering schemes work relative
% to the lecture number.
%
\newcounter{lecnum}
\renewcommand{\thepage}{\thelecnum-\arabic{page}}
\renewcommand{\thesection}{\thelecnum.\arabic{section}}
\renewcommand{\theequation}{\thelecnum.\arabic{equation}}
\renewcommand{\thefigure}{\thelecnum.\arabic{figure}}
\renewcommand{\thetable}{\thelecnum.\arabic{table}}

%
% The following macro is used to generate the header.
%
\newcommand{\lecture}[5]{
   \pagestyle{myheadings}
   \thispagestyle{plain}
   \newpage
   \setcounter{lecnum}{#5}
   \setcounter{page}{1}
   \noindent
   \begin{center}
   \framebox{
      \vbox{\vspace{2mm}
    \hbox to 6.28in { {\bf Masters Bridge Program
                        \hfill Summer 2021} }
       \vspace{4mm}
       \hbox to 6.28in { {\Large \hfill Session {#1}: #2  \hfill} }
       \vspace{2mm}
       \hbox to 6.28in { {\it Instructor: #3 \hfill Contact: #4} }
      \vspace{2mm}}
   }
   \end{center}
   \markboth{Session #1: #2}{Session #1: #2}
   \vspace*{4mm}
}


%Use this command for a figure; it puts a figure in wherever you want it.
%usage: \fig{NUMBER}{SPACE-IN-INCHES}{CAPTION}
\newcommand{\fig}[3]{
			\vspace{#2}
			\begin{center}
			Figure \thelecnum.#1:~#3
			\end{center}
	}
% Use these for theorems, lemmas, proofs, etc.
\newtheorem{theorem}{Theorem}[lecnum]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}[theorem]{Example}
\newtheorem{exercise}[]{Exercise}
\newenvironment{proofof}[1]{{\em Proof of #1.}}{\hfill%\rule{2mm}{2mm}
\qed}

% **** IF YOU WANT TO DEFINE ADDITIONAL MACROS FOR YOURSELF, PUT THEM HERE:
\renewcommand{\P}{\mathbb{P}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\renewcommand{\H}{\mathcal{H}}
\renewcommand{\S}{\mathcal{S}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\MAP}{\mathrm{MAP}}
\newcommand{\z}{\mathbf{z}}
\newcommand{\e}{\mathbf{e}}
\newcommand{\w}{\mathbf{w}}
\newcommand{\x}{\mathbf{x}}
\newcommand{\Rp}{\mathbb{R}_{>0}}
\newcommand{\im}{\mathrm{Im}}
\newcommand{\sign}{\mathrm{sign}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\FF}{\mathcal{F}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\lbr}{\langle}
\newcommand{\rbr}{\rangle}
\newcommand{\indi}{\mathds{1}}

\newcommand{\xmin}{X_{\text{min}}}
\newcommand{\xmax}{X_{\text{max}}}


\begin{document}
\lecture{5}{Continuous random variables: part II}{Bryan Liu}{runjing\_liu@berkeley.edu}{5}

We continue our review of continuous random variables
with further exercises on manipulating their
probability density functions or
cumulative distribution functions.

\section{Max and min of random variables}

\begin{exercise}[distribution and density functions
  of min and max]
  Let $X_1, \ldots, X_n$ be independent random variables.
  Define $\xmax = \max(X_1, ..., X_n)$ and
  $\xmin = \min(X_1, ..., X_n)$.

  \begin{enumerate}[label = (\alph*)]
    \item  Suppose $X_i$ has distribution function $F_i$.
    Express the distribution functions
    of $\xmax$ and $\xmin$
    in terms of the individual distribution functions
     $F_1, ..., F_n$.
    \item Now suppose further that
    each $X_i$ have the same distribution $F$.
    Differentiate the distribution function from (a)
    to find the density functions of $\xmax$ and $\xmin$.
  \end{enumerate}


\end{exercise}

\begin{exercise}(min of independent exponential variables).
  Let $X_1, ..., X_n$ be exponentially distributed
  random variables. Let the rate parameter of $X_i$ be $\lambda_i$.

  Show that $\xmin = \min(X_1, ..., X_n)$ is also
  exponentially distruted with rate parameter
  $\lambda = \lambda_1 + ... + \lambda_n$.
\end{exercise}

\begin{exercise}(min of independent uniform variables).
  Let $X_1, ..., X_n$ be uniformly distributed
  on (0, 1). Compute the density function of $\xmin$.
\end{exercise}

\section{Joint distributions}

Given a pair of random variables, their \textit{joint distribution} is the probability distribution over the plane,
\begin{align*}
  \P(B) = \P((X, Y) \in B)
\end{align*}
where $B\subset\R^2$.

The $\textit{joint density}$ $f(x, y)$ gives the
probability that $(X,Y)$ are in an
infinitesimal neighborhood of $(x, y)$. Probability
on sets $B$ are given by the usual integration formula,
\begin{align*}
  \P((X, Y)\in B) = \int\int_B f(x,y)\; dx\,dy.
\end{align*}

We record some other definitions:
\begin{itemize}
  \item \textbf{Marginal distributions}:
  \begin{align*}
    f_X(x) &= \int_{-\infty}^\infty f(x, y)\; dy \\
    f_Y(y) &= \int_{-\infty}^\infty f(x, y)\; dx.
  \end{align*}
  In other words, given a joint density, we can recover
  the density on $X$ or $Y$ alone by integrating out
  the other variable.
  \item \textbf{Independence}:
  Random variables $X$ and $Y$ are independent if and only if the joint density is a product of the two marginals,
  \begin{align*}
    f(x, y) = f_X(x) f_Y(y).
  \end{align*}
  \item \textbf{Expectations}: Let $g$ be a function that maps $\R^2\mapsto \R$. Then
  \begin{align*}
    \E(g(X, Y)) = \int\int g(x, y) f(x, y)\; dx\, dy.
  \end{align*}
\end{itemize}


\begin{exercise}[two independent uniform random variables]
Let $X, Y$ be independent $\text{Uniform}(0, 1)$ random variables.
\begin{enumerate}[label = (\alph*)]
  \item Find $\P(X^2 + Y^2 \leq 1)$.
  \item Find $\P(X^2 + Y^2 \leq 1 | X + Y \geq 1)$.
  \item Find $\P(Y \leq X^2)$.
\end{enumerate}
\end{exercise}

\begin{exercise}[Uniform on a triangle]
Let $X, Y$ uniformly distribution on the region
$\{(x, y) : 0 < x < y < 1\}$.
\begin{enumerate}[label = (\alph*)]
  \item Find the joint density of $(X, Y)$.
  \item Find marginal densities of $X$ and $Y$.
  \item Are $X$ and $Y$ independent?
  \item Find $E(XY)$.
\end{enumerate}
\end{exercise}


\begin{exercise}[Independent exponential variables]
Let $X$ and $Y$ be independent and exponentially
distributed random variables with parameters $\lambda$ and $\mu$, respectively. Calculate $\P(X<Y)$.
\end{exercise}

\section{Sums of random variables}

Recall that we have already seen that expectations are additive: for any two random variables $X$, $Y$
(regardless of independence), we have
\begin{align*}
  \E(X + Y) = \E(X) + \E(Y)
\end{align*}

We now give a formula for densities.

\fbox{\begin{minipage}{\textwidth}
If $X, Y$ has density $f(x, y)$, then $X + Y$
has density
\begin{align*}
  f_{X+Y}(z) &= \int_{-\infty}^\infty f(x, z-x)\; dx,\\
\end{align*}

If $X$ and $Y$ are independent, then
the formula simplifies to
\begin{align*}
  f_{X+Y}(z) &= \int_{-\infty}^\infty f_X(x)f_Y(z-x)\; dx,\\
\end{align*}

\end{minipage}}

\begin{exercise}[Sum of exponential random variables]
Let $X$ and $Y$ be independent exponentially distributed
random variables with rate $\lambda$. Compute
the density $X + Y$.
\end{exercise}

We record a fact about Normal random variables, to save
us the tedium of doing integrals:

\fbox{\begin{minipage}{\textwidth}
Let $X \sim \mathcal{N}(\mu, \sigma^2)$ and
independently, let $Y\sim\mathcal{N}(\lambda, \tau^2)$.
Then $X + Y$ is Normally distributed with mean
$\mu + \lambda$ and variance $\sigma^2 + \tau^2$.

\end{minipage}}

\begin{exercise}[Distribution of heights]
Suppose heights in a large populatoin are approximately
normally distributed with a mean of 1.78m with a standard
deviaion of 5cm. Suppose a group of 100 people are picked
at random from this population.
\begin{enumerate}[label = (\alph*)]
  \item What is the probability that the tallest person in this group is over 1.93m?
  \item What is the probability that the average height
  of people in the group is over 1.8cm?
  \item Suppose the distribution of heights was not normal, but some other distribution with the given mean and SD. Would the probability to (a) or (b) change,
  or whould they remain approximately the same?
\end{enumerate}

\end{exercise}

\begin{exercise}[Catching BART]
Suppose BART is scheduled to arrive at Downtown
Berkeley station at 8:10am, but its actual arrival time
is normally distributed with mean 8:10am and standard
deviation 40 seconds.
Suppose I try to arrive at the BART station at 8:09am, but
my arrival time is actually a normal distribution with mean
8:09am with standard deviation 30 seconds.
\begin{enumerate}[label = (\alph*)]
  \item What percentage of the time do I arrive at the
  corner before BART is scheduled to arrive?
  \item What percentage of time do I arrive
  at the station before BART?
  \item If arrive at the stop at 8:09am, but BART still
  hasn't come by 8:12AM, what is the probabiliy that I have already missed BART?
\end{enumerate}

\end{exercise}

\end{document}
